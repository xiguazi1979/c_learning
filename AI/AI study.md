# snake
è¯·æä¾›ä¸€ä¸ªCè¯­è¨€æºä»£ç ï¼Œåœ¨ubuntuä¸Šå¯ä»¥ç¼–è¯‘è¿è¡Œä¸€ä¸ªè´ªåƒè›‡æ¸¸æˆ
gcc snake.c -o snake.exe -lncurses
./snake.exe

# æ¨¡å‹è®­ç»ƒè®¡åˆ’
ä¸€ã€å‰æœŸå‡†å¤‡ï¼ˆWin11ç¯å¢ƒé…ç½®ï¼‰
1. å®‰è£…åŸºç¡€å·¥å…·
(1) Python ç¯å¢ƒ

    æ¨è Python 3.10ï¼ˆå…¼å®¹æ€§æœ€å¥½ï¼‰

    ä¸‹è½½åœ°å€ï¼šPython å®˜ç½‘

    å®‰è£…æ—¶å‹¾é€‰ "Add Python to PATH"ï¼ˆæ–¹ä¾¿å‘½ä»¤è¡Œè°ƒç”¨ï¼‰

    éªŒè¯å®‰è£…ï¼š
    bash

    python --version
    pip --version

(2) CUDA & cuDNNï¼ˆGPUåŠ é€Ÿï¼‰

    RTX 3060 12GB æ”¯æŒ CUDA 11.8 æˆ– CUDA 12.x

    å®‰è£…æ­¥éª¤ï¼š

        ä¸‹è½½ NVIDIA CUDA Toolkitï¼ˆæ¨è CUDA 11.8ï¼‰
        â†’ CUDA Toolkit 11.8

        å®‰è£…æ—¶é€‰æ‹© è‡ªå®šä¹‰å®‰è£…ï¼Œç¡®ä¿å‹¾é€‰ CUDA Development Tools

        ä¸‹è½½ cuDNNï¼ˆéœ€æ³¨å†Œ NVIDIA è´¦å·ï¼‰
        â†’ cuDNN 8.6.0 for CUDA 11.x

        è§£å‹ cuDNNï¼Œå¤åˆ¶ binã€includeã€lib åˆ° C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8

        éªŒè¯å®‰è£…ï¼š
        bash

        nvcc --version  # åº”æ˜¾ç¤º CUDA 11.8
        nvidia-smi      # æ£€æŸ¥ GPU æ˜¯å¦è¯†åˆ«

(3) Gitï¼ˆä»£ç ç®¡ç†ï¼‰

    ä¸‹è½½åœ°å€ï¼šGit for Windows

    å®‰è£…åéªŒè¯ï¼š
    bash

    git --version

2. å®‰è£…æ·±åº¦å­¦ä¹ æ¡†æ¶
(1) PyTorchï¼ˆæ¨èï¼‰

    è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£… PyTorch + CUDA 11.8ï¼š
    bash

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

éªŒè¯ GPU æ˜¯å¦å¯ç”¨ï¼š
python

    import torch
    print(torch.cuda.is_available())  # åº”è¿”å› True
    print(torch.cuda.get_device_name(0))  # åº”æ˜¾ç¤º "RTX 3060"

(2) Hugging Face Transformersï¼ˆå¤§æ¨¡å‹å¿…å¤‡ï¼‰
bash

pip install transformers datasets accelerate bitsandbytes peft

(3) å…¶ä»–å®ç”¨å·¥å…·
bash

pip install jupyterlab langchain sentencepiece tiktoken

äºŒã€æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹ï¼ˆé€‚åˆ RTX 3060 12GBï¼‰
1. è¿è¡Œé‡åŒ–æ¨¡å‹ï¼ˆ4bit/8bitï¼‰
(1) ä½¿ç”¨ text-generation-webuiï¼ˆå¯è§†åŒ–ç•Œé¢ï¼‰

    é€‚åˆ 7B/13B é‡åŒ–æ¨¡å‹ï¼ˆChatGLM3ã€Qwen1.5ã€Mistralï¼‰

    å®‰è£…ï¼š
    bash

git clone https://github.com/oobabooga/text-generation-webui
cd text-generation-webui
pip install -r requirements.txt

ä¸‹è½½ 4bit é‡åŒ–æ¨¡å‹ï¼ˆå¦‚ Qwen1.5-7B-Chat-GPTQï¼‰ï¼š
bash

python download-model.py Qwen/Qwen1.5-7B-Chat-GPTQ

å¯åŠ¨ï¼š
bash

    python server.py --model Qwen1.5-7B-Chat-GPTQ --listen --auto-devices

    è®¿é—® http://localhost:7860 è¿›è¡Œäº¤äº’

(2) ä½¿ç”¨ Ollamaï¼ˆå‘½ä»¤è¡Œè¿è¡Œï¼‰

    é€‚åˆ å¿«é€Ÿæµ‹è¯• Llama3ã€Mistral ç­‰

    å®‰è£…ï¼š
    bash

curl -fsSL https://ollama.com/install.sh | sh

è¿è¡Œ 7B é‡åŒ–æ¨¡å‹ï¼š
bash

    ollama pull mistral:7b-instruct-q4_0
    ollama run mistral:7b-instruct-q4_0

ä¸‰ã€æ¨èå­¦ä¹ æ•™ç¨‹ï¼ˆé€‚åˆ Win11 + RTX 3060ï¼‰
1. å…¥é—¨çº§ï¼ˆé›¶åŸºç¡€ï¼‰
æ•™ç¨‹	é“¾æ¥	ç‰¹ç‚¹
å¾®è½¯ AI å¤§æ¨¡å‹é€šè¯†è¯¾ï¼ˆä¸­æ–‡ï¼‰	GitHub	é›¶åŸºç¡€å…¥é—¨ï¼Œæ¶µç›– LLM åŸºç¡€ã€API ä½¿ç”¨
Happy-LLMï¼ˆDatawhaleï¼‰	GitHub	ç³»ç»Ÿæ€§å­¦ä¹ ï¼Œé€‚åˆä¸­æ–‡ç”¨æˆ·
B ç«™ï¼šå¤§æ¨¡å‹è¯¾ç¨‹ L1-1	Bilibili	æš¨å—å¤§å­¦è¯¾ç¨‹ï¼Œç†è®º+å®è·µ
2. å®æˆ˜çº§ï¼ˆå¾®è°ƒ/éƒ¨ç½²ï¼‰
æ•™ç¨‹	é“¾æ¥	ç‰¹ç‚¹
LLM-Universeï¼ˆDatawhaleï¼‰	GitHub	ä»é›¶æ„å»ºçŸ¥è¯†åº“åŠ©æ‰‹
Ollama å¾®è°ƒæŒ‡å—	Collabnix	æœ¬åœ°å¾®è°ƒ Llama3/Mistral
LangChain å®æˆ˜	LangChain Crash Course	æ„å»º AI Agent
å››ã€åç»­å­¦ä¹ è·¯å¾„

    åŸºç¡€æŒæ¡å â†’ å­¦ä¹  LoRA/QLoRA å¾®è°ƒï¼ˆé€‚åˆ 7B æ¨¡å‹ï¼‰

    è¿›é˜¶ â†’ å°è¯• RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ï¼Œå¦‚ LangChain + FAISS

    ç”Ÿäº§çº§ â†’ å­¦ä¹  Docker éƒ¨ç½²ï¼Œå¦‚ FastAPI + vLLM

æ€»ç»“

âœ… å·²å®Œæˆï¼š

    å®‰è£… Python + CUDA + PyTorch

    é…ç½® Hugging Face ç¯å¢ƒ

    è¿è¡Œæœ¬åœ° 7B é‡åŒ–æ¨¡å‹ï¼ˆQwen/Mistralï¼‰

ğŸ“š æ¨èå­¦ä¹ ï¼š

    æ–°æ‰‹ â†’ å¾®è½¯ AI å¤§æ¨¡å‹é€šè¯†è¯¾

    å®æˆ˜ â†’ LLM-Universe

    å¾®è°ƒ â†’ Ollama å¾®è°ƒæŒ‡å—

ä½ çš„ RTX 3060 12GB å®Œå…¨å¯ä»¥èƒœä»» 7B æ¨¡å‹çš„æ¨ç†å’Œè½»é‡å¾®è°ƒï¼ŒæŒ‰è¿™ä¸ªè·¯çº¿é€æ­¥æ·±å…¥å³å¯ï¼
